from collections import defaultdict

import torch


class FP16Monitor:
    def __init__(self, model):
        self.model = model
        self.hooks = []
        self.stats = defaultdict(dict)

        # 注册前向传播钩子
        for name, module in model.named_modules():
            hook = self._create_hook(name)
            self.hooks.append(module.register_forward_hook(hook))

    def _create_hook(self, name):
        def hook(module, input, output):
            if isinstance(output, tuple):
                output = output[0]
            if output.dtype == torch.float16:
                self.stats[name] = {
                    "max": output.max().item(),
                    "min": output.min().item(),
                    "has_inf": torch.isinf(output).any().item(),
                    "has_nan": torch.isnan(output).any().item(),
                }

        return hook

    def get_problematic_modules(self):
        return {
            name: stats
            for name, stats in self.stats.items()
            if stats["has_inf"] or stats["has_nan"] or abs(stats["max"]) > 1e4 or abs(stats["min"]) > 1e4
        }

    def __del__(self):
        for hook in self.hooks:
            hook.remove()
